{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Vectorizing your environments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vectorized Environments\n*Vectorized environments* are environments that run multiple independent\ncopies of the same environment in parallel using\n[multiprocessing](https://docs.python.org/3/library/multiprocessing.html)_.\nVectorized environments take as input a batch of actions, and return a\nbatch of observations. This is particularly useful, for example, when\nthe policy is defined as a neural network that operates over a batch of\nobservations. Gymnasium provides two types of vectorized environments:\n\n-  ``gymnasium.vector.SyncVectorEnv``, where the different copies of the\n   environment are executed sequentially.\n-  ``gymnasium.vector.AsyncVectorEnv``, where the different copies of\n   the environment are executed in parallel using\n   [multiprocessing](https://docs.python.org/3/library/multiprocessing.html)_.\n   This creates one process per copy.\n\nSimilar to ``gymnasium.make``, you can run a vectorized version of a\nregistered environment using the ``gymnasium.vector.make`` function.\nThis runs multiple copies of the same environment (in parallel, by\ndefault).\n\nThe following example runs 3 copies of the ``CartPole-v1`` environment\nin parallel, taking as input a vector of 3 binary actions (one for each\ncopy of the environment), and returning an array of 3 observations\nstacked along the first dimension, with an array of rewards returned by\neach copy, and an array of booleans indicating if the episode in each\nparallel environment has ended.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import timeit\n\nimport gymnasium as gym\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nenvs = gym.vector.make(\"CartPole-v1\", num_envs=3)\nenvs.reset()\nactions = np.array([1, 0, 1])\nobservations, rewards, termination, truncation, infos = envs.step(actions)\n\nobservations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "termination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "truncation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "infos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The function ``gymnasium.vector.make`` is meant to be used only in basic\ncases (e.g.\u00a0running multiple copies of the same registered environment).\nFor any other use cases, please use either the ``SyncVectorEnv`` for\nsequential execution or ``AsyncVectorEnv`` for parallel execution. These\nuse cases may include:\n\n-  Running multiple instances of the same environment with different\n   parameters (e.g.\u00a0``\"Pendulum-v0\"`` with different values for the\n   gravity).\n-  Running multiple instances of an unregistered environment (e.g.\u00a0a\n   custom environment).\n-  Using a wrapper on some (but not all) environment copies.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating a vectorized environment\n\nTo create a vectorized environment that runs multiple environment\ncopies, you can wrap your parallel environments inside\n``gymnasium.vector.SyncVectorEnv`` (for sequential execution), or\n``gymnasium.vector.AsyncVectorEnv`` (for parallel execution, with\n[multiprocessing](https://docs.python.org/3/library/multiprocessing.html)_).\nThese vectorized environments take as input a list of callables\nspecifying how the copies are created.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "envs = gym.vector.AsyncVectorEnv(\n    [\n        lambda: gym.make(\"CartPole-v1\"),\n        lambda: gym.make(\"CartPole-v1\"),\n        lambda: gym.make(\"CartPole-v1\"),\n    ]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, to create a vectorized environment of multiple copies of\nthe same registered environment, you can use the function\n``gymnasium.vector.make()``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "envs = gym.vector.make(\"CartPole-v1\", num_envs=3)  # Equivalent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To enable automatic batching of actions and observations, all of the\nenvironment copies must share the same ``action_space`` and\n``observation_space``. However, all of the parallel environments are not\nrequired to be exact copies of one another. For example, you can run 2\ninstances of ``Pendulum-v1`` with different values for gravity in a\nvectorized environment with:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "env = gym.vector.AsyncVectorEnv(\n    [lambda: gym.make(\"Pendulum-v1\", g=9.81), lambda: gym.make(\"Pendulum-v1\", g=1.62)]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "See the ``Observation & Action spaces`` section for more information\nabout automatic batching.\n\nWhen using ``AsyncVectorEnv`` with either the ``spawn`` or\n``forkserver`` start methods, you must wrap your code containing the\nvectorized environment with ``if __name__ == \"__main__\":``. See [this\ndocumentation](https://docs.python.org/3/library/multiprocessing.html#the-spawn-and-forkserver-start-methods)_\nfor more information.\n\n.. code:: python\n\n    if __name__ == \"__main__\":\n        envs = gym.vector.make(\"CartPole-v1\", num_envs=3, context=\"spawn\")\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Working with vectorized environments\n\nWhile standard Gymnasium environments take a single action and return a\nsingle observation (with a reward, and boolean indicating termination),\nvectorized environments take a *batch of actions* as input, and return a\n*batch of observations*, together with an array of rewards and booleans\nindicating if the episode ended in each environment copy.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "envs = gym.vector.make(\"CartPole-v1\", num_envs=3)\nenvs.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "actions = np.array([1, 0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "observations, rewards, termination, truncation, infos = envs.step(actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "termination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "truncation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "infos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vectorized environments are compatible with any environment, regardless\nof the action and observation spaces (e.g.\u00a0container spaces like\n``gymnasium.spaces.Dict``, or any arbitrarily nested spaces). In\nparticular, vectorized environments can automatically batch the\nobservations returned by ``VectorEnv.reset`` and ``VectorEnv.step`` for\nany standard Gymnasium ``Space`` (e.g.\u00a0``gymnasium.spaces.Box``,\n``gymnasium.spaces.Discrete``, ``gymnasium.spaces.Dict``, or any nested\nstructure thereof). Similarly, vectorized environments can take batches\nof actions from any standard Gymnasium ``Space``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class DictEnv(gym.Env):\n    observation_space = gym.spaces.Dict(\n        {\n            \"position\": gym.spaces.Box(-1.0, 1.0, (3,), np.float32),\n            \"velocity\": gym.spaces.Box(-1.0, 1.0, (2,), np.float32),\n        }\n    )\n    action_space = gym.spaces.Dict(\n        {\n            \"fire\": gym.spaces.Discrete(2),\n            \"jump\": gym.spaces.Discrete(2),\n            \"acceleration\": gym.spaces.Box(-1.0, 1.0, (2,), np.float32),\n        }\n    )\n\n    def reset(self):\n        return self.observation_space.sample()\n\n    def step(self, action):\n        observation = self.observation_space.sample()\n        return observation, 0.0, False, False, {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "envs = gym.vector.AsyncVectorEnv([lambda: DictEnv()] * 3)\nenvs.observation_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "envs.action_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "envs.reset()\nactions = {\n    \"fire\": np.array([1, 1, 0]),\n    \"jump\": np.array([0, 1, 0]),\n    \"acceleration\": np.random.uniform(-1.0, 1.0, size=(3, 2)),\n}\nobservations, rewards, termination, truncation, infos = envs.step(actions)\nobservations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The environment copies inside a vectorized environment automatically\ncall ``gymnasium.Env.reset`` at the end of an episode. In the following\nexample, the episode of the 3rd copy ends after 2 steps (the agent fell\nin a hole), and the parallel environment gets reset (observation ``0``).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "envs = gym.vector.make(\"FrozenLake-v1\", num_envs=3, is_slippery=False)\nenvs.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "observations, rewards, termination, truncation, infos = envs.step(np.array([1, 2, 2]))\nobservations, rewards, termination, truncation, infos = envs.step(np.array([1, 2, 1]))\nobservations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "termination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Vectorized environments will return ``infos`` in the form of a\n  dictionary where each value is an array of length ``num_envs`` and the\n  *i-th* value of the array represents the info of the *i-th*\n  environment.\n| Each ``key`` of the info is paired with a boolean mask ``_key``\n  representing whether or not the *i-th* environment has data.\n| If the *dtype* of the returned info is whether ``int``, ``float``,\n  ``bool`` or any *dtype* inherited from ``np.number``, an array of the\n  same *dtype* will be returned. Otherwise, the array will have *dtype*\n  ``object``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "envs = gym.vector.make(\"CartPole-v1\", num_envs=3)\nobservations, infos = envs.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "actions = np.array([1, 0, 1])\nobservations, rewards, termination, truncation, infos = envs.step(actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "while not any(np.logical_or(termination, truncation)):\n    observations, rewards, termination, truncation, infos = envs.step(actions)\n\ntermination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "infos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Observation & Action spaces\n\nLike any Gymnasium environment, vectorized environments contain the two\nproperties ``VectorEnv.observation_space`` and\n``VectorEnv.action_space`` to specify the observation and action spaces\nof the environments. Since vectorized environments operate on multiple\nenvironment copies, where the actions taken and observations returned by\nall of the copies are batched together, the observation and action\n*spaces* are batched as well so that the input actions are valid\nelements of ``VectorEnv.action_space``, and the observations are valid\nelements of ``VectorEnv.observation_space``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "envs = gym.vector.make(\"CartPole-v1\", num_envs=3)\nenvs.observation_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "envs.action_space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to appropriately batch the observations and actions in\nvectorized environments, the observation and action spaces of all of the\ncopies are required to be identical.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "envs = gym.vector.AsyncVectorEnv(\n    [lambda: gym.make(\"CartPole-v1\"), lambda: gym.make(\"MountainCar-v0\")]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, sometimes it may be handy to have access to the observation and\naction spaces of a particular copy, and not the batched spaces. You can\naccess those with the properties ``VectorEnv.single_observation_space``\nand ``VectorEnv.single_action_space`` of the vectorized environment.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "envs = gym.vector.make(\"CartPole-v1\", num_envs=3)\nenvs.single_observation_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "envs.single_action_space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is convenient, for example, if you instantiate a policy. In the\nfollowing example, we use ``VectorEnv.single_observation_space`` and\n``VectorEnv.single_action_space`` to define the weights of a linear\npolicy. Note that, thanks to the vectorized environment, we can apply\nthe policy directly to the whole batch of observations with a single\ncall to ``policy``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gymnasium.spaces.utils import flatdim\nfrom scipy.special import softmax\n\n\ndef policy(weights, observations):\n    logits = np.dot(observations, weights)\n    return softmax(logits, axis=1)\n\n\nenvs = gym.vector.make(\"CartPole-v1\", num_envs=3)\n\nweights = np.random.randn(\n    flatdim(envs.single_observation_space), envs.single_action_space.n\n)\n\nobservations, infos = envs.reset()\nactions = policy(weights, observations).argmax(axis=1)\nobservations, rewards, termination, truncation, infos = envs.step(actions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Intermediate Usage\n\n### Shared memory\n\n``AsyncVectorEnv`` runs each environment copy inside an individual\nprocess. At each call to ``AsyncVectorEnv.reset`` or\n``AsyncVectorEnv.step``, the observations of all of the parallel\nenvironments are sent back to the main process. To avoid expensive\ntransfers of data between processes, especially with large observations\n(e.g.\u00a0images), ``AsyncVectorEnv`` uses a shared memory by default\n(``shared_memory=True``) that processes can write to and read from at\nminimal cost. This can increase the throughput of the vectorized\nenvironment.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "env_fns = [lambda: gym.make(\"BreakoutNoFrameskip-v4\")] * 5\nenvs = gym.vector.AsyncVectorEnv(env_fns, shared_memory=False)\nenvs.reset()\ntimeit(\"envs.step(envs.action_space.sample()\", number=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "envs = gym.vector.AsyncVectorEnv(env_fns, shared_memory=True)\nenvs.reset()\ntimeit(\"envs.step(envs.action_space.sample())\", number=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exception handling\n\nBecause sometimes things may not go as planned, the exceptions raised in\nany given environment copy are re-raised in the vectorized environment,\neven when the copy runs in parallel with ``AsyncVectorEnv``. This way,\nyou can choose how to handle these exceptions yourself (with\n``try  except``).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class ErrorEnv(gym.Env):\n    observation_space = gym.spaces.Box(-1.0, 1.0, (2,), np.float32)\n    action_space = gym.spaces.Discrete(2)\n\n    def reset(self):\n        return np.zeros((2,), dtype=np.float32), {}\n\n    def step(self, action):\n        if action == 1:\n            raise ValueError(\"An error occurred.\")\n        observation = self.observation_space.sample()\n        return observation, 0.0, False, False, {}\n\n\nenvs = gym.vector.AsyncVectorEnv([lambda: ErrorEnv()] * 3)\nobservations, infos = envs.reset()\nobservations, rewards, termination, termination, infos = envs.step(np.array([0, 0, 1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Usage\n\n### Custom spaces\n\nVectorized environments will batch actions and observations if they are\nelements from standard Gymnasium spaces, such as\n``gymnasium.spaces.Box``, ``gymnasium.spaces.Discrete``, or\n``gymnasium.spaces.Dict``. However, if you create your own environment\nwith a custom action and/or observation space (inheriting from\n``gymnasium.Space``), the vectorized environment will not attempt to\nautomatically batch the actions/observations, and instead, it will\nreturn the raw tuple of elements from all parallel environments.\n\nIn the following example, we create a new environment ``SMILESEnv``,\nwhose observations are strings representing the\n[SMILES](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system)_\nnotation of a molecular structure, with a custom observation space\n``SMILES``. The observations returned by the vectorized environment are\ncontained in a tuple of strings.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class SMILES(gym.Space):\n    def __init__(self, symbols):\n        super().__init__()\n        self.symbols = symbols\n\n    def __eq__(self, other):\n        return self.symbols == other.symbols\n\n\nclass SMILESEnv(gym.Env):\n    observation_space = SMILES(\"][()CO=\")\n    action_space = gym.spaces.Discrete(7)\n\n    def reset(self):\n        self._state = \"[\"\n        return self._state\n\n    def step(self, action):\n        self._state += self.observation_space.symbols[action]\n        reward = terminated = action == 0\n        return self._state, float(reward), terminated, False, {}\n\n\nenvs = gym.vector.AsyncVectorEnv([lambda: SMILESEnv()] * 3, shared_memory=False)\nenvs.reset()\nobservations, rewards, termination, truncation, infos = envs.step(np.array([2, 5, 4]))\nobservations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Custom observation and action spaces may inherit from the\n``gymnasium.Space`` class. However, most use cases should be covered by\nthe existing space classes (e.g.\u00a0``gymnasium.spaces.Box``,\n``gymnasium.spaces.Discrete``, etc\u2026), and container classes\n(``gymnasium.spaces.Tuple`` and ``gymnasium.spaces.Dict``). Moreover,\nsome implementations of reinforcement learning algorithms might not\nhandle custom spaces properly. Use custom spaces with care.\n\nIf you use ``AsyncVectorEnv`` with a custom observation space, you must\nset ``shared_memory=False``, since shared memory and automatic batching\nare not compatible with custom spaces. In general, if you use custom\nspaces with ``AsyncVectorEnv``, the elements of those spaces must be\n``pickleable``.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}